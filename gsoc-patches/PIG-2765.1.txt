Index: test/org/apache/pig/test/TestCubeOperator.java
===================================================================
--- test/org/apache/pig/test/TestCubeOperator.java	(revision 1352776)
+++ test/org/apache/pig/test/TestCubeOperator.java	(working copy)
@@ -82,6 +82,9 @@
 		tuple("u10,women,green,apple"),
 		tuple("u11,men,red,apple"),
 		tuple("u12,women,green,mango"));
+
+	data.set("input2", 
+		tuple("dog", "miami", "white", "pet", 5));
     }
 
     @AfterClass
@@ -93,7 +96,7 @@
 	// basic correctness test
 	String query =
 		"a = load 'input' USING mock.Storage() as (x:chararray,y:chararray,z:long);" +
-			"b = cube a by (x,y);" +
+			"b = cube a by cube(x,y);" +
 			"c = foreach b generate flatten(group) as (type,location), COUNT(cube) as count, SUM(cube.z) as total;" +
 			"store c into 'output' using mock.Storage();";
 	Util.registerMultiLineQuery(pigServer, query);
@@ -123,13 +126,75 @@
     }
 
     @Test
+    public void testRollupBasic() throws IOException {
+	// basic correctness test
+	String query =
+		"a = load 'input' USING mock.Storage() as (x:chararray,y:chararray,z:long);" +
+			"b = cube a by rollup(x,y);" +
+			"c = foreach b generate flatten(group) as (type,location), COUNT(cube) as count, SUM(cube.z) as total;" +
+			"store c into 'output' using mock.Storage();";
+	Util.registerMultiLineQuery(pigServer, query);
+
+	Set<Tuple> expected = ImmutableSet.of(
+		tf.newTuple(ImmutableList.of("cat", "miami", (long)1, (long)18)),
+		tf.newTuple(ImmutableList.of("cat", "naples", (long)1, (long)9)),
+		tf.newTuple(ImmutableList.of("cat", "NULL", (long)2, (long)27)),
+		tf.newTuple(ImmutableList.of("dog", "miami", (long)1, (long)12)),
+		tf.newTuple(ImmutableList.of("dog", "tampa", (long)1, (long)14)),
+		tf.newTuple(ImmutableList.of("dog", "naples", (long)1, (long)5)),
+		tf.newTuple(ImmutableList.of("dog", "NULL", (long)3, (long)31)),
+		tf.newTuple(ImmutableList.of("turtle", "tampa", (long)1, (long)4)),
+		tf.newTuple(ImmutableList.of("turtle", "naples", (long)1, (long)1)),
+		tf.newTuple(ImmutableList.of("turtle", "NULL", (long)2, (long)5)),
+		tf.newTuple(ImmutableList.of("NULL", "NULL", (long)7, (long)63))
+		);
+
+	List<Tuple> out = data.get("output");
+	for( Tuple tup : out ) {
+	    assertTrue(expected+" contains "+tup, expected.contains(tup));
+	}
+    }
+
+    @Test
+    public void testCubeAndRollup() throws IOException {
+	// basic correctness test
+	String query =
+		"a = load 'input2' USING mock.Storage() as (v:chararray,w:chararray,x:chararray,y:chararray,z:long);" +
+			"b = cube a by cube(v,w), rollup(x,y);" +
+			"c = foreach b generate flatten(group) as (type,location,color,category), COUNT(cube) as count, SUM(cube.z) as total;" +
+			"store c into 'output' using mock.Storage();";
+	Util.registerMultiLineQuery(pigServer, query);
+
+	Set<Tuple> expected = ImmutableSet.of(
+		tf.newTuple(ImmutableList.of("dog", "miami", "white", "pet", (long)1, (long)5)),
+		tf.newTuple(ImmutableList.of("dog", "NULL", "white", "pet", (long)1, (long)5)),
+		tf.newTuple(ImmutableList.of("NULL", "miami", "white", "pet", (long)1, (long)5)),
+		tf.newTuple(ImmutableList.of("NULL", "NULL", "white", "pet", (long)1, (long)5)),
+		tf.newTuple(ImmutableList.of("dog", "miami", "white", "NULL", (long)1, (long)5)),
+		tf.newTuple(ImmutableList.of("dog", "NULL", "white", "NULL", (long)1, (long)5)),
+		tf.newTuple(ImmutableList.of("NULL", "miami", "white", "NULL", (long)1, (long)5)),
+		tf.newTuple(ImmutableList.of("NULL", "NULL", "white", "NULL", (long)1, (long)5)),
+		tf.newTuple(ImmutableList.of("dog", "miami", "NULL", "NULL", (long)1, (long)5)),
+		tf.newTuple(ImmutableList.of("dog", "NULL", "NULL", "NULL", (long)1, (long)5)),
+		tf.newTuple(ImmutableList.of("NULL", "miami", "NULL", "NULL", (long)1, (long)5)),
+		tf.newTuple(ImmutableList.of("NULL", "NULL", "NULL", "NULL", (long)1, (long)5))
+		);
+
+	List<Tuple> out = data.get("output");
+	for( Tuple tup : out ) {
+	    assertTrue(expected+" contains "+tup, expected.contains(tup));
+	}
+
+    }
+
+    @Test
     public void testCubeMultipleIAliases() throws IOException {
 	// test for input alias to cube being assigned multiple times
 	String query = 
 		"a = load 'input' USING mock.Storage() as (x:chararray,y:chararray,z:long);" +
 			"a = load 'input' USING mock.Storage() as (x,y:chararray,z:long);" +
 			"a = load 'input' USING mock.Storage() as (x:chararray,y:chararray,z:long);" +
-			"b = cube a by (x,y);" + 
+			"b = cube a by cube(x,y);" + 
 			"c = foreach b generate flatten(group) as (type,location), COUNT(cube) as count, SUM(cube.z) as total;" +
 			"store c into 'output' using mock.Storage();";
 
@@ -165,7 +230,7 @@
 	String query = 
 		"a = load 'input' USING mock.Storage() as (x:chararray,y:chararray,z:long);" +
 			"b = foreach a generate x as type,y as location,z as number;" +
-			"c = cube b by (type,location);" + 
+			"c = cube b by cube(type,location);" + 
 			"d = foreach c generate flatten(group) as (type,location), COUNT(cube) as count, SUM(cube.number) as total;" +
 			"store d into 'output' using mock.Storage();";
 
@@ -201,7 +266,7 @@
 	String query = 
 		"a = load 'input' USING mock.Storage() as (x:chararray,y:chararray,z:long);" +
 			"b = limit a 2;" +
-			"c = cube b by (x,y);" + 
+			"c = cube b by cube(x,y);" + 
 			"d = foreach c generate flatten(group) as (x,y), SUM(cube.z) as total;" +
 			"store d into 'output' using mock.Storage();";
 
@@ -229,7 +294,7 @@
 	String query = 
 		"a = load 'input' USING mock.Storage() as (x:chararray,y:chararray);" +
 			"b = foreach a generate x as type,y as location;" +
-			"c = cube b by (*);" + 
+			"c = cube b by cube(*);" + 
 			"d = foreach c generate flatten(group) as (type,location), COUNT(cube) as count;" +
 			"store d into 'output' using mock.Storage();";
 
@@ -265,7 +330,7 @@
 	String query = 
 		"a = load 'input' USING mock.Storage() as (x:chararray,y:chararray,z:long);" +
 			"b = foreach a generate x as type,y as location, z as number;" +
-			"c = cube b by ($0..$1);" + 
+			"c = cube b by cube($0..$1);" + 
 			"d = foreach c generate flatten(group) as (type,location), COUNT(cube) as count, SUM(cube.number) as total;" +
 			"store d into 'output' using mock.Storage();";
 
@@ -300,7 +365,7 @@
 	// test for cube operator with duplicate dimensions
 	String query = "a = load 'input' USING mock.Storage() as (x:chararray,y:chararray,z:long);"
 		+ "b = foreach a generate x as type,y as location, z as number;"
-		+ "c = cube b by ($0..$1,$0..$1);"
+		+ "c = cube b by cube($0..$1,$0..$1);"
 		+ "d = foreach c generate flatten(group), COUNT(cube) as count, SUM(cube.number) as total;"
 		+ "store d into 'output' using mock.Storage();";
 
@@ -322,7 +387,7 @@
 	String query = 
 		"a = load 'input' USING mock.Storage() as (x:chararray,y:chararray,z:long);" +
 			"b = filter a by x == 'dog';" +
-			"c = cube b by (x,y);" + 
+			"c = cube b by cube(x,y);" + 
 			"d = foreach c generate flatten(group), COUNT(cube) as count, SUM(cube.z) as total;" +
 			"store d into 'output' using mock.Storage();";
 
@@ -353,7 +418,7 @@
 	String query = 
 		"a = load 'input' USING mock.Storage() as (x:chararray,y:chararray,z:long);" +
 			"b = order a by $2;" +
-			"c = cube b by (x,y);" + 
+			"c = cube b by cube(x,y);" + 
 			"d = foreach c generate flatten(group), COUNT(cube) as count, SUM(cube.z) as total;" +
 			"store d into 'output' using mock.Storage();";
 
@@ -389,7 +454,7 @@
 		"a = load 'input1' USING mock.Storage() as (a1:chararray,b1,c1,d1); " +
 			"b = load 'input' USING mock.Storage() as (a2,b2,c2:long,d2:chararray);" +
 			"c = join a by a1, b by d2;" +
-			"d = cube c by ($4,$5);" + 
+			"d = cube c by cube($4,$5);" + 
 			"e = foreach d generate flatten(group), COUNT(cube) as count, SUM(cube.c2) as total;" +
 			"store e into 'output' using mock.Storage();";
 
@@ -424,7 +489,7 @@
 			"b = load 'input' USING mock.Storage() as (a2,b2,c2:long,d2:chararray);" +
 			"c = cogroup a by a1, b by d2;" +
 			"d = foreach c generate flatten(a), flatten(b);" +
-			"e = cube d by (a2,b2);" +
+			"e = cube d by cube(a2,b2);" +
 			"f = foreach e generate flatten(group), COUNT(cube) as count, SUM(cube.c2) as total;" +
 			"store f into 'output' using mock.Storage();";
 
@@ -452,11 +517,43 @@
     }
 
     @Test
+    public void testRollupAfterCogroup() throws IOException {
+	// test for cubing on co-grouped relation
+	String query = 
+		"a = load 'input1' USING mock.Storage() as (a1:chararray,b1,c1,d1); " +
+			"b = load 'input' USING mock.Storage() as (a2,b2,c2:long,d2:chararray);" +
+			"c = cogroup a by a1, b by d2;" +
+			"d = foreach c generate flatten(a), flatten(b);" +
+			"e = cube d by rollup(a2,b2);" +
+			"f = foreach e generate flatten(group), COUNT(cube) as count, SUM(cube.c2) as total;" +
+			"store f into 'output' using mock.Storage();";
+
+	Util.registerMultiLineQuery(pigServer, query);
+
+	Set<Tuple> expected = ImmutableSet.of(
+		tf.newTuple(ImmutableList.of("cat", "miami", (long)1, (long)18)),
+		tf.newTuple(ImmutableList.of("cat", "NULL", (long)1, (long)18)),
+		tf.newTuple(ImmutableList.of("dog", "miami", (long)1, (long)12)),
+		tf.newTuple(ImmutableList.of("dog", "tampa", (long)1, (long)14)),
+		tf.newTuple(ImmutableList.of("dog", "NULL", (long)2, (long)26)),
+		tf.newTuple(ImmutableList.of("turtle", "tampa", (long)1, (long)4)),
+		tf.newTuple(ImmutableList.of("turtle", "naples", (long)1, (long)1)),
+		tf.newTuple(ImmutableList.of("turtle", "NULL", (long)2, (long)5)),
+		tf.newTuple(ImmutableList.of("NULL", "NULL", (long)5, (long)49))
+		);
+
+	List<Tuple> out = data.get("output");
+	for( Tuple tup : out ) {
+	    assertTrue(expected+" contains "+tup, expected.contains(tup));
+	}
+    }
+
+    @Test
     public void testIllustrate() throws IOException {
 	// test for illustrate
 	String query = 
 		"a = load 'input' USING mock.Storage() as (a1:chararray,b1:chararray,c1:long); " +
-			"b = cube a by (a1,b1);";
+			"b = cube a by cube(a1,b1);";
 
 	Util.registerMultiLineQuery(pigServer, query);
 	Map<Operator, DataBag> examples = pigServer.getExamples("b");
@@ -464,11 +561,11 @@
     }
 
     @Test
-    public void testExplain() throws IOException {
+    public void testExplainCube() throws IOException {
 	// test for explain
 	String query = 
 		"a = load 'input' USING mock.Storage() as (a1:chararray,b1:chararray,c1:long); " +
-			"b = cube a by (a1,b1);";
+			"b = cube a by cube(a1,b1);";
 
 	Util.registerMultiLineQuery(pigServer, query);
 	ByteArrayOutputStream baos = new ByteArrayOutputStream();
@@ -478,11 +575,25 @@
     }
 
     @Test
+    public void testExplainRollup() throws IOException {
+	// test for explain
+	String query = 
+		"a = load 'input' USING mock.Storage() as (a1:chararray,b1:chararray,c1:long); " +
+			"b = cube a by rollup(a1,b1);";
+
+	Util.registerMultiLineQuery(pigServer, query);
+	ByteArrayOutputStream baos = new ByteArrayOutputStream();
+	PrintStream ps = new PrintStream(baos);
+	pigServer.explain("b", ps);
+	assertTrue(baos.toString().contains("RollupDimensions('NULL')"));
+    }
+
+    @Test
     public void testDescribe() throws IOException {
 	// test for describe
 	String query = 
 		"a = load 'input' USING mock.Storage() as (a1:chararray,b1:chararray,c1:long); " +
-			"b = cube a by (a1,b1);";
+			"b = cube a by cube(a1,b1);";
 
 	Util.registerMultiLineQuery(pigServer, query);
 	Schema sch = pigServer.dumpSchema("b");
Index: test/org/apache/pig/test/TestRollupDimensions.java
===================================================================
--- test/org/apache/pig/test/TestRollupDimensions.java	(revision 0)
+++ test/org/apache/pig/test/TestRollupDimensions.java	(revision 0)
@@ -0,0 +1,57 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.pig.test;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertTrue;
+
+import java.io.IOException;
+import java.util.Set;
+
+import org.apache.pig.builtin.RollupDimensions;
+import org.apache.pig.data.DataBag;
+import org.apache.pig.data.Tuple;
+import org.apache.pig.data.TupleFactory;
+import org.junit.Test;
+
+import com.google.common.collect.ImmutableList;
+import com.google.common.collect.ImmutableSet;
+
+public class TestRollupDimensions {
+
+    private static TupleFactory TF = TupleFactory.getInstance();
+
+    @Test
+    public void testCube() throws IOException {
+	Tuple t = TF.newTuple(ImmutableList.of("a", "b", "c"));
+	Set<Tuple> expected = ImmutableSet.of(
+		TF.newTuple(ImmutableList.of("a", "b", "c")),
+		TF.newTuple(ImmutableList.of("a", "b", "NULL")),
+		TF.newTuple(ImmutableList.of("a", "NULL", "NULL")),
+		TF.newTuple(ImmutableList.of("NULL", "NULL", "NULL"))
+		);
+
+	RollupDimensions rd = new RollupDimensions("NULL");
+	DataBag bag = rd.exec(t);
+	assertEquals(bag.size(), expected.size());
+
+	for (Tuple tup : bag) {
+	    assertTrue(expected.contains(tup));
+	}
+    }
+}
Index: test/org/apache/pig/parser/TestQueryLexer.java
===================================================================
--- test/org/apache/pig/parser/TestQueryLexer.java	(revision 1352776)
+++ test/org/apache/pig/parser/TestQueryLexer.java	(working copy)
@@ -48,7 +48,7 @@
         
         // While we can check more conditions, such as type of each token, for now I think the following
         // is enough. If the token type is wrong, it will be most likely caught by the parser.
-        Assert.assertEquals( 415, tokenCount );
+        Assert.assertEquals( 419, tokenCount );
         Assert.assertEquals( 0, lexer.getNumberOfSyntaxErrors() );
     }
     
Index: test/org/apache/pig/parser/TestLexer.pig
===================================================================
--- test/org/apache/pig/parser/TestLexer.pig	(revision 1352776)
+++ test/org/apache/pig/parser/TestLexer.pig	(working copy)
@@ -62,7 +62,7 @@
 
 I = foreach A generate flatten(B::c);
 
-J = CUBE A BY ($0, $1, $2, $3);
+J = CUBE A BY CUBE($0, $1), ROLLUP($2, $3);
 
 CMD = `ls -l`;
 A = stream through CMD;
Index: test/org/apache/pig/parser/TestQueryParser.java
===================================================================
--- test/org/apache/pig/parser/TestQueryParser.java	(revision 1352776)
+++ test/org/apache/pig/parser/TestQueryParser.java	(working copy)
@@ -210,10 +210,26 @@
     }
     
     @Test
+    public void testCubeNegative5() throws IOException, RecognitionException {
+	// syntax error - specifying just dimensions 
+    	String query = "x = load 'cubedata' as (a, b, c, d); " +
+    				   "y = cube x by (a, b, c), CUBE(c);";
+    	shouldFail( query );
+    }
+    
+    @Test
+    public void testCubeNegative6() throws IOException, RecognitionException {
+	// syntax error - dangling dimension 
+    	String query = "x = load 'cubedata' as (a, b, c, d); " +
+    				   "y = cube x by CUBE(a, b, c), y, ROLLUP(c);";
+    	shouldFail( query );
+    }
+    
+    @Test
     public void testCubePositive1() throws IOException, RecognitionException {
 	// syntactically correct
     	String query = "x = load 'cubedata' as (a, b, c, d);" + 
-    				   "y = cube x by (a, b, c);" +
+    				   "y = cube x by cube(a, b, c);" +
     				   "z = foreach y generate flatten(group) as (a, b, c), COUNT(x) as count;" +
     				   "store z into 'cube_output';";
     	shouldPass( query );
@@ -223,7 +239,7 @@
     public void testCubePositive2() throws IOException, RecognitionException {
 	// all columns using *
     	String query = "x = load 'cubedata' as (a, b, c, d);" + 
-    				   "y = cube x by (*);" +
+    				   "y = cube x by rollup(*), rollup($2..$3);" +
     				   "z = foreach y generate flatten(group) as (a, b, c, d), COUNT(x) as count;" +
     				   "store z into 'cube_output';";
     	shouldPass( query );
@@ -234,7 +250,7 @@
     public void testCubePositive3() throws IOException, RecognitionException {
 	// range projection
     	String query = "x = load 'cubedata' as (a, b, c, d);" + 
-    				   "y = cube x by ($0, $1);" +
+    				   "y = cube x by cube($0, $1);" +
     				   "z = foreach y generate flatten(group) as (a, b), COUNT(x) as count;" +
     				   "store z into 'cube_output';";
     	shouldPass( query );
Index: test/org/apache/pig/parser/TestParser.pig
===================================================================
--- test/org/apache/pig/parser/TestParser.pig	(revision 1352776)
+++ test/org/apache/pig/parser/TestParser.pig	(working copy)
@@ -66,8 +66,8 @@
 B = GROUP A ALL using 'collected';
 
 --cube
-C = CUBE A BY (a, b);
-CC = CUBE A BY (*);
+C = CUBE A BY CUBE(a, b);
+CC = CUBE A BY ROLLUP(*);
 
 --join
 E = join A by $0, B by $0 using 'replicated';
Index: test/org/apache/pig/parser/TestLogicalPlanGenerator.java
===================================================================
--- test/org/apache/pig/parser/TestLogicalPlanGenerator.java	(revision 1352776)
+++ test/org/apache/pig/parser/TestLogicalPlanGenerator.java	(working copy)
@@ -301,7 +301,7 @@
     @Test
     public void testCubeBasic() {
 	String query = "a = load 'input' as (x:chararray,y:chararray,z:long);"
-	        + "b = cube a by (x,y);"
+	        + "b = cube a by cube(x,y);"
 	        + "c = foreach b generate flatten(group) as (x,y), COUNT(cube) as count, SUM(cube.z) as total;"
 	        + "store c into 'output';";
 	generateLogicalPlan(query);
@@ -312,7 +312,7 @@
 	String query = "a = load 'input' as (x:chararray,y:chararray,z:long);"
 	        + "a = load 'input' as (x,y:chararray,z:long);"
 	        + "a = load 'input' as (x:chararray,y:chararray,z:long);"
-	        + "b = cube a by (x,y);"
+	        + "b = cube a by rollup(x,y);"
 	        + "c = foreach b generate flatten(group) as (x,y), COUNT(cube) as count, SUM(cube.z) as total;"
 	        + "store c into 'c';";
 	generateLogicalPlan(query);
@@ -322,7 +322,7 @@
     public void testCubeAfterForeach() {
 	String query = "a = load 'input' as (x:chararray,y:chararray,z:long);"
 	        + "b = foreach a generate x as type,y as location,z as number;"
-	        + "c = cube b by (type,location);"
+	        + "c = cube b by cube(type,location);"
 	        + "d = foreach c generate flatten(group) as (type,location), COUNT(cube) as count, SUM(cube.number) as total;"
 	        + "store d into 'd';";
 	generateLogicalPlan(query);
Index: src/org/apache/pig/parser/AstPrinter.g
===================================================================
--- src/org/apache/pig/parser/AstPrinter.g	(revision 1352776)
+++ src/org/apache/pig/parser/AstPrinter.g	(working copy)
@@ -214,10 +214,21 @@
 ;
 
 cube_by_clause
-    : ^( BY { sb.append(" ").append($BY.text).append(" ("); } 
-    cube_by_expr ( { sb.append(", "); } cube_by_expr )* { sb.append(")"); } )
+    : ^( BY { sb.append(" ").append($BY.text); } cube_or_rollup )
 ;
 
+cube_or_rollup
+	: cube_rollup_list ( { sb.append(", "); } cube_rollup_list )* 
+;
+
+cube_rollup_list
+	: ^( ( CUBE { sb.append($CUBE.text).append("("); } | ROLLUP { sb.append($ROLLUP.text).append("("); } ) cube_by_expr_list { sb.append(")"); }) 
+;
+
+cube_by_expr_list
+ : ( cube_by_expr ( { sb.append(", "); } cube_by_expr )* )
+;
+
 cube_by_expr 
     : col_range | expr | STAR { sb.append($STAR.text); }
 ;
@@ -574,6 +585,7 @@
     | FILTER    { sb.append($FILTER.text); }
     | FOREACH   { sb.append($FOREACH.text); }
     | CUBE      { sb.append($CUBE.text); }
+    | ROLLUP    { sb.append($ROLLUP.text); }
     | MATCHES   { sb.append($MATCHES.text); }
     | ORDER     { sb.append($ORDER.text); }
     | DISTINCT  { sb.append($DISTINCT.text); }
Index: src/org/apache/pig/parser/AliasMasker.g
===================================================================
--- src/org/apache/pig/parser/AliasMasker.g	(revision 1352776)
+++ src/org/apache/pig/parser/AliasMasker.g	(working copy)
@@ -246,9 +246,21 @@
 ;
 
 cube_by_clause
-    : ^( BY cube_by_expr+ )
+    : ^( BY cube_or_rollup )
 ;
 
+cube_or_rollup
+	: cube_rollup_list+
+;
+
+cube_rollup_list
+	: ^( ( CUBE | ROLLUP ) cube_by_expr_list )
+;
+
+cube_by_expr_list
+  : cube_by_expr+
+;
+
 cube_by_expr 
     : col_range | expr | STAR 
 ;
@@ -591,6 +603,7 @@
     | FILTER
     | FOREACH
     | CUBE
+    | ROLLUP
     | MATCHES
     | ORDER
     | DISTINCT
Index: src/org/apache/pig/parser/LogicalPlanGenerator.g
===================================================================
--- src/org/apache/pig/parser/LogicalPlanGenerator.g	(revision 1352776)
+++ src/org/apache/pig/parser/LogicalPlanGenerator.g	(working copy)
@@ -467,15 +467,16 @@
 ;
 
 // Sets the current operator as CUBE and creates LogicalExpressionPlans based on the user input.
-// Ex: a = CUBE inp BY (x,y);
-// For the above example this grammar creates LogicalExpressionPlan with ProjectExpression for x and y dimensions.
-// inputIndex keeps track of input dataset (which will be useful when cubing is performed over multiple datasets).
+// Ex: x = CUBE inp BY CUBE(a,b), ROLLUP(c,d);
+// For the above example this grammar creates LogicalExpressionPlan with ProjectExpression for x,y and c,d dimensions.
+// It also outputs the order of operations i.e in this case CUBE operation followed by ROLLUP operation
 // These inputs are passed to buildCubeOp methods which then builds the logical plan for CUBE operator.
 // If user specifies STAR or RANGE expression for dimensions then it will be expanded inside buildCubeOp.
 cube_clause returns[String alias]
 scope {
   LOCube cubeOp;
   MultiMap<Integer, LogicalExpressionPlan> cubePlans;
+  List<String> operations;
   int inputIndex;
 }
 scope GScope;
@@ -483,34 +484,57 @@
   $cube_clause::cubeOp = builder.createCubeOp();
   $GScope::currentOp = $cube_clause::cubeOp;
   $cube_clause::cubePlans = new MultiMap<Integer, LogicalExpressionPlan>();
-  int oldStatementIndex = $statement::inputIndex;
+  $cube_clause::operations = new ArrayList<String>();
 }
-@after { $statement::inputIndex = oldStatementIndex; }
  : ^( CUBE cube_item )
  {
   SourceLocation loc = new SourceLocation( (PigParserNode)$cube_clause.start );
   $alias = builder.buildCubeOp( loc, $cube_clause::cubeOp, $statement::alias, 
-    $statement::inputAlias, $cube_clause::cubePlans );
+    $statement::inputAlias, $cube_clause::operations, $cube_clause::cubePlans );
  }
 ;
 
 cube_item
  : rel ( cube_by_clause 
      { 
-            $cube_clause::cubePlans.put( $cube_clause::inputIndex, $cube_by_clause.plans );
+            $cube_clause::cubePlans = $cube_by_clause.plans;
+            $cube_clause::operations = $cube_by_clause.operations;
      }
   )
-  {
+;
+
+cube_by_clause returns[List<String> operations, MultiMap<Integer, LogicalExpressionPlan> plans]
+@init {
+    $operations = new ArrayList<String>();
+	  $plans = new MultiMap<Integer, LogicalExpressionPlan>();
+}
+ : ^( BY cube_or_rollup { $operations = $cube_or_rollup.operations; $plans = $cube_or_rollup.plans; })
+;
+
+cube_or_rollup returns[List<String> operations, MultiMap<Integer, LogicalExpressionPlan> plans]
+@init {
+	$operations = new ArrayList<String>();
+	$plans = new MultiMap<Integer, LogicalExpressionPlan>();
+}
+ : ( cube_rollup_list { 
+     $operations.add($cube_rollup_list.operation); 
+     $plans.put( $cube_clause::inputIndex, $cube_rollup_list.plans); 
      $cube_clause::inputIndex++;
-     $statement::inputIndex++;  
+   } )+
+;
+
+cube_rollup_list returns[String operation, List<LogicalExpressionPlan> plans]
+@init {
+	$plans = new ArrayList<LogicalExpressionPlan>();
   }
+ : ^( ( CUBE { $operation = "CUBE"; } | ROLLUP { $operation = "ROLLUP"; } ) cube_by_expr_list { $plans = $cube_by_expr_list.plans; } ) 
 ;
 
-cube_by_clause returns[List<LogicalExpressionPlan> plans]
+cube_by_expr_list returns[List<LogicalExpressionPlan> plans]
 @init {
     $plans = new ArrayList<LogicalExpressionPlan>();
 }
- : ^( BY ( cube_by_expr { $plans.add( $cube_by_expr.plan ); } )+ )
+ : ( cube_by_expr { $plans.add( $cube_by_expr.plan ); } )+
 ;
 
 cube_by_expr returns[LogicalExpressionPlan plan]
@@ -521,8 +545,7 @@
  | expr[$plan]
  | STAR 
    {
-       builder.buildProjectExpr( new SourceLocation( (PigParserNode)$STAR ), $plan, $GScope::currentOp, 
-           $statement::inputIndex, null, -1 );
+       builder.buildProjectExpr( new SourceLocation( (PigParserNode)$STAR ), $plan, $GScope::currentOp, 0, null, -1 );
    }
 ;
 
@@ -1681,6 +1704,8 @@
     | ORDER { $id = $ORDER.text; }
     | DISTINCT { $id = $DISTINCT.text; }
     | COGROUP { $id = $COGROUP.text; }
+    | CUBE { $id = $CUBE.text; }
+    | ROLLUP { $id = $ROLLUP.text; }
     | JOIN { $id = $JOIN.text; }
     | CROSS { $id = $CROSS.text; }
     | UNION { $id = $UNION.text; }
Index: src/org/apache/pig/parser/AstValidator.g
===================================================================
--- src/org/apache/pig/parser/AstValidator.g	(revision 1352776)
+++ src/org/apache/pig/parser/AstValidator.g	(working copy)
@@ -265,9 +265,21 @@
 ;
 
 cube_by_clause
-    : ^( BY cube_by_expr+ )
+    : ^( BY cube_or_rollup )
 ;
 
+cube_or_rollup
+	: cube_rollup_list+
+;
+
+cube_rollup_list
+	: ^( ( CUBE | ROLLUP ) cube_by_expr_list )
+;
+
+cube_by_expr_list
+  : cube_by_expr+
+;
+
 cube_by_expr 
     : col_range | expr | STAR 
 ;
@@ -583,6 +595,7 @@
     | FILTER
     | FOREACH
     | CUBE
+    | ROLLUP
     | MATCHES
     | ORDER
     | DISTINCT
Index: src/org/apache/pig/parser/QueryLexer.g
===================================================================
--- src/org/apache/pig/parser/QueryLexer.g	(revision 1352776)
+++ src/org/apache/pig/parser/QueryLexer.g	(working copy)
@@ -84,6 +84,9 @@
 CUBE    : 'CUBE'
 ;
 
+ROLLUP	: 'ROLLUP'
+;
+
 DISTINCT : 'DISTINCT'
 ;
 
Index: src/org/apache/pig/parser/QueryParser.g
===================================================================
--- src/org/apache/pig/parser/QueryParser.g	(revision 1352776)
+++ src/org/apache/pig/parser/QueryParser.g	(working copy)
@@ -584,12 +584,18 @@
 cube_item : rel ( cube_by_clause )
 ;
 
-cube_by_clause : BY^ cube_by_expr_list
+cube_by_clause : BY^ cube_or_rollup
 ;
 
+cube_or_rollup : cube_rollup_list ( COMMA cube_rollup_list )*
+                -> cube_rollup_list+
+;
+
+cube_rollup_list : ( CUBE | ROLLUP )^ cube_by_expr_list
+;
+
 cube_by_expr_list : LEFT_PAREN cube_by_expr ( COMMA cube_by_expr )* RIGHT_PAREN
                        -> cube_by_expr+
-                        | cube_by_expr
 ;
 
 cube_by_expr : col_range  | expr | STAR
@@ -730,6 +736,7 @@
     | FILTER
     | FOREACH
     | CUBE
+    | ROLLUP
     | ORDER
     | DISTINCT
     | COGROUP
Index: src/org/apache/pig/parser/LogicalPlanBuilder.java
===================================================================
--- src/org/apache/pig/parser/LogicalPlanBuilder.java	(revision 1352776)
+++ src/org/apache/pig/parser/LogicalPlanBuilder.java	(working copy)
@@ -39,6 +39,7 @@
 import org.apache.pig.builtin.CubeDimensions;
 import org.apache.pig.builtin.PigStorage;
 import org.apache.pig.builtin.RANDOM;
+import org.apache.pig.builtin.RollupDimensions;
 import org.apache.pig.data.BagFactory;
 import org.apache.pig.data.DataBag;
 import org.apache.pig.data.DataType;
@@ -376,29 +377,123 @@
     
     String buildCubeOp(SourceLocation loc, LOCube op, String alias,
 	    String inputAlias,
+	    List<String> operations,
 	    MultiMap<Integer, LogicalExpressionPlan> expressionPlans)
 	    throws ParserValidationException {
 
+	// check if continuously occurring cube operations be combined
+	combineCubeOperations((ArrayList<String>) operations, expressionPlans);
+
 	// set the expression plans for cube operator and build cube operator
 	op.setExpressionPlans(expressionPlans);
+	op.setOperations(operations);
 	buildOp(loc, op, alias, inputAlias, null);
 	expandAndResetVisitor(loc, op);
-
 	try {
-	    alias = convertCubeToFGPlan(loc, op, inputAlias, op.getExpressionPlans());
+	    alias = convertCubeToFGPlan(loc, op, inputAlias, operations, expressionPlans);
         } catch (FrontendException e) {
             throw new ParserValidationException( intStream, loc, e );
         }
         return alias;
     }
 
+    // if multiple CUBE operations occur continuously then it can be combined together
+    // CUBE rel BY CUBE(a,b), CUBE(c,d); ===> CUBE rel BY CUBE(a,b,c,d);
+    private void combineCubeOperations(ArrayList<String> operations,
+	    MultiMap<Integer, LogicalExpressionPlan> expressionPlans) {
+
+	int startIdx = -1;
+	int endIdx = -1;
+	int i = 0;
+	boolean isMerged = false;
+
+	//scan and perform merge of column projections
+	for(i = 0; i < operations.size(); i++) {
+	    if ( (startIdx == -1) && (operations.get(i).equals("CUBE") == true) ) {
+		startIdx = i;
+		continue;
+	    }
+	    if( operations.get(i).equals("CUBE") == true ) {
+		endIdx = i;
+	    }
+	    else {
+		if( endIdx > startIdx ) {
+		    mergeAndMarkForDelete(operations, expressionPlans, startIdx, endIdx);
+		    isMerged = true;
+		    startIdx = -1;
+		    endIdx = -1;
+		}
+		else {
+		    startIdx = -1;
+		    endIdx = -1;
+		}
+	    }
+	}
+
+	//corner case 
+	if( endIdx > startIdx ) {
+	    isMerged = true;
+	    mergeAndMarkForDelete(operations, expressionPlans, startIdx, endIdx);
+	}
+
+	//if merged then remove the column projections that were marked for deletion
+	if(isMerged) {
+	    performDeletion(expressionPlans, operations);
+	}
+    }
+
+    private void performDeletion(
+	    MultiMap<Integer, LogicalExpressionPlan> expressionPlans,
+	    ArrayList<String> operations) {
+
+	MultiMap<Integer, LogicalExpressionPlan> ep = new MultiMap<Integer, LogicalExpressionPlan>();
+	List<String> op = new ArrayList<String>();
+	int idx = 0;
+	//rearranging indices
+	for( int i = 0; i < operations.size(); i++ ) {
+	    if( operations.get(i) != null ) {
+		op.add(idx, operations.get(i));
+	    }
+
+	    if( expressionPlans.get(i) != null ) {
+		ep.put(idx, expressionPlans.get(i));
+		idx++;
+	    }
+	}
+
+	//performing deletions
+	operations.clear();
+	operations.addAll(op);
+
+	expressionPlans.clear();
+	for(Integer i : ep.keySet()) {
+	    expressionPlans.put(i, ep.get(i));
+	}
+    }
+
+    //performs merging of dimensions of merged cube operation
+    //Ex: CUBE(a,b), CUBE(c,d) ==> CUBE(a,b,c,d)
+    //in the above example CUBE operator and dimensions are merged
+    private void mergeAndMarkForDelete(
+	    ArrayList<String> operations,
+	    MultiMap<Integer, LogicalExpressionPlan> expressionPlans, int startIdx,
+	    int endIdx) {
+	//mark for delete
+	for( int i = startIdx+1; i <= endIdx; i++) {
+	    expressionPlans.put(startIdx, expressionPlans.get(i));
+	    expressionPlans.removeKey(i);
+	    operations.remove(i);
+	    operations.add(i, null);
+	}
+    }
+
      // This function creates logical plan for foreach and groupby operators. 
      // It connects the predecessors of cube operator with foreach plan and
      // disconnects cube operator from the logical plan. It also connects foreach
      // plan with groupby plan.
     private String convertCubeToFGPlan(SourceLocation loc, LOCube op,
 	    String inputAlias,
-	    MultiMap<Integer, LogicalExpressionPlan> expressionPlans)
+	    List<String> operations, MultiMap<Integer, LogicalExpressionPlan> expressionPlans)
 	    throws FrontendException {
 
 	LOForEach foreach = new LOForEach(plan);
@@ -411,7 +506,7 @@
 	// Get all column attributes from the input relation.
 	// Create ProjectExpression for all columns. Based on the
 	// dimensions specified by the user, specified columns will be attached
-	// to CubeDimension UDF and rest will be pushed down
+	// to CubeDimension/RollupDimension UDF and rest will be pushed down
 	List<Operator> inpOpers = foreach.getPlan().getPredecessors(foreach);
 	List<LogicalExpressionPlan> allExprPlan = new ArrayList<LogicalExpressionPlan>();
 	for (Operator oper : inpOpers) {
@@ -428,13 +523,13 @@
 	    }
 	}
 
+	//iterate over all operations and generate corresponding UDFs
+	for(int operIdx = 0; operIdx < operations.size(); operIdx++)
+	{
 	List<LogicalExpressionPlan> lexpPlanList = new ArrayList<LogicalExpressionPlan>();
 	List<LogicalExpression> lexpList = new ArrayList<LogicalExpression>();
 
-	// TODO: current implementation only supports star schema
-	// if snow-flake schema is to be supported then dimensions
-	// from multiple tables should be retrieved here.
-	lexpPlanList.addAll(expressionPlans.get(0));
+	    lexpPlanList.addAll(expressionPlans.get(operIdx));	    
 
 	// If duplicates exists in the dimension list then exception is thrown
 	checkDuplicateProject(lexpPlanList);
@@ -453,16 +548,40 @@
 		    colAlias = ((ProjectExpression) lexpList.get(i)).getFieldSchema().alias;
 		}
 
-		if (colAlias.equals(((ProjectExpression) lexp).getColAlias()) == true) {
+		    String projExpAlias = null;
+		    try {
+			projExpAlias = ((ProjectExpression) lexp).getColAlias();
+		    }
+		    catch (ClassCastException e) {
+			//if it is not projection then it should be UserFuncExpr.
+			//ignore and continue till next ProjExpr is encountered
+			continue;
+		    }
+		    if (colAlias.equals(projExpAlias) == true) {
+			allExprPlan.remove(j);
+		    }
+		    else {
+			// if projected exp alias is a namespaced alias
+			if(projExpAlias.lastIndexOf(":") != -1) {
+			    projExpAlias = projExpAlias.substring(projExpAlias.lastIndexOf(":") + 1, 
+				    projExpAlias.length());
+			    if(colAlias.equals(projExpAlias) == true) {
 		    allExprPlan.remove(j);
 		}
 	    }
-
+		    }
+		}
 	}
 
 	// Create UDF with user specified dimensions 
 	LogicalExpressionPlan uexpPlan = new LogicalExpressionPlan();
+	    if(operations.get(operIdx).equals("CUBE")) {
 	new UserFuncExpression(uexpPlan, new FuncSpec(CubeDimensions.class.getName(), "NULL"), lexpList);
+	    }
+	    else {
+		new UserFuncExpression(uexpPlan, new FuncSpec(RollupDimensions.class.getName(), "NULL"), lexpList);
+	    }
+
 	for (LogicalExpressionPlan lexp : lexpPlanList) {
 	    Iterator<Operator> it = lexp.getOperators();
 	    while (it.hasNext()) {
@@ -471,12 +590,13 @@
 	}
 	// Add the UDF to logical expression plan that contains dependent
 	// attributes (pushed down from input columns)
-	allExprPlan.add(0, uexpPlan);
+	    allExprPlan.add(operIdx, uexpPlan);
+	}
 
 	// If the operator is a UserFuncExpression then set the flatten flags.
 	List<Boolean> flattenFlags = new ArrayList<Boolean>();
-	for (int i = 0; i < allExprPlan.size(); i++) {
-	    List<Operator> opers = allExprPlan.get(i).getSources();
+	for (int idx = 0; idx < allExprPlan.size(); idx++) {
+	    List<Operator> opers = allExprPlan.get(idx).getSources();
 	    for (Operator oper : opers) {
 		if (oper instanceof ProjectExpression) {
 		    flattenFlags.add(false);
@@ -490,7 +610,7 @@
 	String falias = null;
 	try {
 	    buildGenerateOp(loc, (LOForEach) foreach, (LOGenerate) gen, 
-		    operators, allExprPlan, flattenFlags, null);
+		    operators, allExprPlan, flattenFlags, getUserSchema(allExprPlan));
 	    falias = buildForeachOp(loc, (LOForEach) foreach, "cube",inputAlias, innerPlan);
 	} catch (ParserValidationException pve) {
 	    throw new FrontendException(pve);
@@ -504,17 +624,13 @@
 	// Get the output schema of foreach operator and reconstruct the
 	// LogicalExpressionPlan for each dimensional attributes
 	MultiMap<Integer, LogicalExpressionPlan> exprPlansCopy = new MultiMap<Integer, LogicalExpressionPlan>();
-	LogicalSchema fSchema = null;
-	fSchema = foreach.getSchema();
 
-	List<LogicalFieldSchema> lfSchemas = fSchema.getFields();
-	for (LogicalFieldSchema lfSchema : lfSchemas) {
+	for(LogicalExpressionPlan exp : expressionPlans.values()) {
+	    LogicalExpression lexp = (LogicalExpression)exp.getSources().get(0);
 	    LogicalExpressionPlan epGrp = new LogicalExpressionPlan();
-	    if (lfSchema.alias.contains("dimensions::") == true) {
-		new ProjectExpression(epGrp, 0, lfSchema.alias, groupby);
+	    new ProjectExpression(epGrp, 0, lexp.getFieldSchema().alias, groupby);
 		exprPlansCopy.put(0, epGrp);
 	    }
-	}
 
 	// build group by operator
 	try {
@@ -525,6 +641,33 @@
 	}
     }
     
+    // User defined schema for generate operator. If not specified output schema of 
+    // UDF will be used which will prefix "dimensions" namespace to all fields
+    private List<LogicalSchema> getUserSchema(List<LogicalExpressionPlan> allExprPlan) throws FrontendException {
+	List<LogicalSchema> genOutputSchema = new ArrayList<LogicalSchema>();
+	for (int i = 0; i < allExprPlan.size(); i++) {
+	    List<Operator> opers = allExprPlan.get(i).getSources();
+	    for (Operator oper : opers) {
+
+		// add a logical schema for dimensions that are pushed from predecessor of cube/rollup
+		if (oper instanceof ProjectExpression) {
+		    LogicalSchema output = new LogicalSchema();
+		    output.addField(new LogicalFieldSchema( ((ProjectExpression) oper).getColAlias(), null, DataType.NULL) );
+		    genOutputSchema.add(output);
+		} else if (oper instanceof UserFuncExpression) {
+		    // add logical schema for dimensions specified in cube/rollup operator
+		    LogicalSchema output = new LogicalSchema();
+		    for(Operator op : ((UserFuncExpression) oper).getPlan().getSinks()) {
+			output.addField(new LogicalFieldSchema(((ProjectExpression) op).getFieldSchema()));
+		    }
+		    genOutputSchema.add(output);
+		}
+
+	    }
+	}
+	return genOutputSchema;
+    }
+
     private List<LogicalExpression> getProjectExpList(List<LogicalExpressionPlan> lexpPlanList,
 	    LogicalRelationalOperator lro) throws FrontendException {
 
Index: src/org/apache/pig/newplan/logical/relational/LOCube.java
===================================================================
--- src/org/apache/pig/newplan/logical/relational/LOCube.java	(revision 1352776)
+++ src/org/apache/pig/newplan/logical/relational/LOCube.java	(working copy)
@@ -32,27 +32,53 @@
  * CUBE operator implementation for data cube computation.
  * <p> 
  * Cube operator syntax
- * <pre>{@code alias = CUBE rel BY (col_ref);}
+ * <pre>{@code alias = CUBE rel BY { CUBE | ROLLUP }(col_ref) [, { CUBE | ROLLUP }(col_ref) ...];}
  * alias - output alias 
  * CUBE - operator
  * rel - input relation
  * BY - operator
+ * CUBE | ROLLUP - cube or rollup operation
  * col_ref - column references or * or range in the schema referred by rel
  * </pre> </p>
  * <p>
- * The cube computation code sample at {@link org.apache.pig.builtin.CubeDimensions} 
- * can now be represented like below
+ * The cube computation and rollup computation using UDFs {@link org.apache.pig.builtin.CubeDimensions}
+ * and {@link org.apache.pig.builtin.RollupDimensions} can now be represented like below
  * <pre>{@code
- * events = LOAD '/logs/events' USING EventLoader() AS (lang, event, app_id, total);
- * eventcube = CUBE events BY (lang, event, app_id);
- * result = FOREACH eventcube GENERATE FLATTEN(group) as (lang, event, app_id),
+ * events = LOAD '/logs/events' USING EventLoader() AS (lang, event, app_id, event_id, total);
+ * eventcube = CUBE events BY CUBE(lang, event), ROLLUP(app_id, event_id);
+ * result = FOREACH eventcube GENERATE FLATTEN(group) as (lang, event),
  *          COUNT_STAR(cube), SUM(cube.total);
  * STORE result INTO 'cuberesult';
  * }</pre>
+ * 
+ * In the above example, CUBE(lang, event) will generate all combinations of aggregations 
+ * {(lang, event), (lang, NULL), (NULL, event), (NULL, NULL)}. For n dimensions, 2^n combinations
+ * of aggregations will be generated.
+ * 
+ * Similarly, ROLLUP(app_id, event_id) will generate aggregations from the most detailed to the
+ * most general (grandtotal) level in the hierarchical order like {(app_id, event_id), (app_id, NULL) , (NULL, NULL)}.
+ * For n dimensions, n+1 combinations of aggregations will be generated.  
+ * 
+ * The output of the above example will have the following combinations of aggregations 
+ * {(lang, event, app_id, event_id),
+ * (lang, NULL, app_id, event_id),
+ * (NULL, event, app_id, event_id),
+ * (NULL, NULL, app_id, event_id),
+ * (lang, event, app_id, NULL),
+ * (lang, NULL, app_id, NULL),
+ * (NULL, event, app_id, NULL),
+ * (NULL, NULL, app_id, NULL),
+ * (lang, event, NULL, NULL),
+ * (lang, NULL, NULL, NULL),
+ * (NULL, event, NULL, NULL),
+ * (NULL, NULL, NULL, NULL),}
+ * 
+ * Total number of combinations will be ( 2^n * (n+1) )
  * </p>
  */
 public class LOCube extends LogicalRelationalOperator {
     private MultiMap<Integer, LogicalExpressionPlan> mExpressionPlans;
+    private List<String> operations;
 
     public LOCube(LogicalPlan plan) {
 	super("LOCube", plan);
@@ -121,4 +147,12 @@
     public List<Operator> getInputs(LogicalPlan plan) {
 	return plan.getPredecessors(this);
     }
+
+    public List<String> getOperations() {
+	return operations;
+    }
+
+    public void setOperations(List<String> operations) {
+	this.operations = operations;
+    }
 }
Index: src/org/apache/pig/builtin/RollupDimensions.java
===================================================================
--- src/org/apache/pig/builtin/RollupDimensions.java	(revision 0)
+++ src/org/apache/pig/builtin/RollupDimensions.java	(revision 0)
@@ -0,0 +1,101 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.pig.builtin;
+
+import java.io.IOException;
+import java.util.List;
+
+import org.apache.pig.EvalFunc;
+import org.apache.pig.backend.executionengine.ExecException;
+import org.apache.pig.data.BagFactory;
+import org.apache.pig.data.DataBag;
+import org.apache.pig.data.DataType;
+import org.apache.pig.data.Tuple;
+import org.apache.pig.data.TupleFactory;
+import org.apache.pig.impl.logicalLayer.FrontendException;
+import org.apache.pig.impl.logicalLayer.schema.Schema;
+import org.apache.pig.impl.logicalLayer.schema.Schema.FieldSchema;
+
+import com.google.common.collect.Lists;
+
+/**
+ * Produces a DataBag with hierarchy of values (from the most detailed level of aggregation
+ * to most general level of aggregation) of the specified dimensions
+ * For example, (a, b, c) will produce the following bag:
+ * <pre>
+ * { (a, b, c), (a, b, null), (a, null, null), (null, null, null) }
+ * </pre>
+ */
+public class RollupDimensions extends EvalFunc<DataBag> {
+
+    private static BagFactory bf = BagFactory.getInstance();
+    private static TupleFactory tf = TupleFactory.getInstance();
+    private final String allMarker;
+    private final String unknown = "unknown";
+
+    public RollupDimensions() {
+	this(null);
+    }
+
+    public RollupDimensions(String allMarker) {
+	super();
+	this.allMarker = allMarker;
+    }
+
+    @Override
+    public DataBag exec(Tuple tuple) throws IOException {
+	List<Tuple> result = Lists.newArrayListWithCapacity((int) Math.pow(2, tuple.size()));
+	Tuple nonNullTuple = convertNullToUnknown(tuple);
+	result.add(nonNullTuple);
+	recursivelyRollup(result, nonNullTuple, nonNullTuple.getAll().size() - 1);
+	return bf.newDefaultBag(result);
+    }
+
+    // if the dimension values contain null then replace it with "unknown" value
+    // since null will be used for rollups
+    private Tuple convertNullToUnknown(Tuple tuple) throws ExecException {
+	Tuple nonNullTup = tf.newTuple(tuple.getAll());
+	int idx = 0;
+	for(Object obj : tuple.getAll()) {
+	    if( (obj == null) ) {
+		nonNullTup.set(idx, unknown);
+	    }
+	    idx++;
+	}
+	return nonNullTup;
+    }
+
+    private void recursivelyRollup(List<Tuple> result, Tuple input, int index) throws ExecException {
+	if( index >= 0 ) {
+	    Tuple newT = tf.newTuple(input.getAll());
+	    newT.set(index, allMarker);
+	    result.add(newT);
+	    recursivelyRollup(result, newT, index - 1);
+	}
+    }
+
+    @Override
+    public Schema outputSchema(Schema input) {
+	try {
+	    return new Schema(new FieldSchema("dimensions", input, DataType.BAG));
+	} catch (FrontendException e) {
+	    // we are specifying BAG explicitly, so this should not happen.
+	    throw new RuntimeException(e);
+	}
+    }
+}
